{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63515170-201d-4c78-a1d5-ac7b8e810652",
   "metadata": {},
   "source": [
    "https://python.langchain.com/en/latest/getting_started/getting_started.html\n",
    "\n",
    "https://gist.github.com/segestic/4822f3765147418fc084a250598c1fe6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "818a76a5-ab3d-4f16-8335-d8d573c7cdb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566a01a3-79cc-4df0-ace5-c6616a44ec15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LIB_PATH   = './src'\n",
    "MODEL_PATH = './models/gpt4all-lora-quantized-ggml.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb9d50a-fc6d-4bf3-b3a9-0de062147633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(LIB_PATH)\n",
    "\n",
    "import pytorch_common.util as pu\n",
    "import os\n",
    "\n",
    "from llm   import LlamaCpp\n",
    "from agent import AgentBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b9786a-e7e5-40c0-83f3-c6afdb50edac",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5877fd81-2ed8-480f-a1e1-3679d9f08462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_CSE_ID']       = 'FILL ME'\n",
    "os.environ['GOOGLE_API_KEY']      = 'FILL ME'\n",
    "os.environ['WOLFRAM_ALPHA_APPID'] = 'FILL ME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "432b8f97-3420-42d2-9778-ef1aca924e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RootLogger root (INFO)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pu.LoggerBuilder().on_console().build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac76228-8a14-4bfc-bc92-b9b4def7db42",
   "metadata": {},
   "source": [
    "## Create agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78ac0582-3a8d-4b71-8466-00b53f7610fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from ./models/gpt4all-lora-quantized-ggml.bin\n",
      "llama.cpp: can't use mmap because tensors are not aligned; convert to new format to avoid this\n",
      "llama_model_load_internal: format     = ggmf v1 (old version with no mmap support)\n",
      "llama_model_load_internal: n_vocab    = 32001\n",
      "llama_model_load_internal: n_ctx      = 4096\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size = 4113744.11 KB\n",
      "llama_model_load_internal: mem required  = 5809.33 MB (+ 1026.00 MB per state)\n",
      "...................................................................................................\n",
      ".\n",
      "llama_init_from_file: kv self size  = 2048.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "agent = AgentBuilder.create(\n",
    "    model      = LlamaCpp(MODEL_PATH),\n",
    "    capacities = ['wolfram-alpha'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed7585e-a332-448f-8dd6-a7d1b692c7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 14:35:55,872 - INFO - Promp(757): Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Wolfram Alpha: A wrapper around Wolfram Alpha. Useful for when you need to answer questions about Math, Science, Technology, Culture, Society and Everyday Life. Input should be a search query.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Wolfram Alpha]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: what is 13 plus 2?\n",
      "Thought:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "agent.run(\"what is 13 plus 2?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
